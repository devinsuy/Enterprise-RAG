{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install boto3 sagemaker langchain langchain-community langchain-core faiss-cpu requests opensearch-py sentence-transformers langchain-text-splitters requests-aws4auth qdrant-client -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import  modules and libraries \n",
    "import json\n",
    "import boto3\n",
    "import pandas as pd\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants \n",
    "MODEL_ID = \"anthropic.claude-3-haiku-20240307-v1:0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "bedrock_client = boto3.client('bedrock-runtime', region_name=\"us-east-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO : Include Test API Call into this notebook "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_user_prompt = \"\"\"\n",
    "### Here is a user prompt:\n",
    "{query}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_prompt(query_args):\n",
    "    prompt_with_query = baseline_user_prompt.replace(\"{query}\", query_args['query'])\n",
    "    \n",
    "    # This format doesn't matter much now, but we will use it later to \n",
    "    # persist chat history for continuous dialogue\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": prompt_with_query\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    return messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eval LLM \n",
    "def query_eval_llm(messages):\n",
    "    response = bedrock_client.invoke_model(\n",
    "        modelId=MODEL_ID,\n",
    "        body=json.dumps({\n",
    "            'anthropic_version': 'bedrock-2023-05-31', # This is required to use chat style messages object \n",
    "            'messages': messages,\n",
    "            'max_tokens': 3000,\n",
    "            'temperature': 0.1, \n",
    "            'top_p': 0.9,\n",
    "            'top_k' : 2,\n",
    "        })\n",
    "    )\n",
    "    response_body = json.loads(response.get('body').read())\n",
    "    \n",
    "    return response_body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "qdrant_rag_chain_eval = (\n",
    "    RunnableMap(\n",
    "         {\"query\": RunnablePassthrough()}\n",
    "    )\n",
    "    | process_prompt\n",
    "    | query_eval_llm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_query_1.query</th>\n",
       "      <th>test_query_1.response</th>\n",
       "      <th>test_query_2.query</th>\n",
       "      <th>test_query_2.response</th>\n",
       "      <th>test_query_3.query</th>\n",
       "      <th>test_query_3.response</th>\n",
       "      <th>test_query_4.query</th>\n",
       "      <th>test_query_4.response</th>\n",
       "      <th>test_query_5.query</th>\n",
       "      <th>test_query_5.response</th>\n",
       "      <th>...</th>\n",
       "      <th>config.COARSE_SEARCH_KWARGS.lambda_mult</th>\n",
       "      <th>config.COARSE_SEARCH_TYPE</th>\n",
       "      <th>config.DOWNLOAD_PATH</th>\n",
       "      <th>config.FILE_KEY</th>\n",
       "      <th>config.MAX_DOC_COUNT</th>\n",
       "      <th>config.MODEL_ID</th>\n",
       "      <th>config.RERANKER_TOP_N</th>\n",
       "      <th>config.RETRIEVER</th>\n",
       "      <th>config.SELF_QUERY_API</th>\n",
       "      <th>config.SELF_QUERY_MODEL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\nI enjoy asian fusion food and I am a vegetar...</td>\n",
       "      <td>&lt;search_quality_reflection&gt;\\nThe new search re...</td>\n",
       "      <td>\\nI have a peanut allergy but I like thai food...</td>\n",
       "      <td>&lt;search_quality_reflection&gt;\\nThe focused query...</td>\n",
       "      <td>\\nSuggest a low-carb breakfast recipe that inc...</td>\n",
       "      <td>&lt;search_quality_reflection&gt;\\nThe third search ...</td>\n",
       "      <td>\\nSuggest a healthy dinner recipe for two peop...</td>\n",
       "      <td>&lt;search_quality_reflection&gt;\\nThe additional se...</td>\n",
       "      <td>\\nI am on a ketogenic diet and need a dinner r...</td>\n",
       "      <td>Unfortunately I could not find any recipes in ...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>mmr</td>\n",
       "      <td>data</td>\n",
       "      <td>recipes_w_cleaning_time_combined_features.parquet</td>\n",
       "      <td>150</td>\n",
       "      <td>anthropic.claude-3-sonnet-20240229-v1:0</td>\n",
       "      <td>1</td>\n",
       "      <td>self_query_chain</td>\n",
       "      <td>OpenAI</td>\n",
       "      <td>gpt-4o</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  test_query_1.query  \\\n",
       "0  \\nI enjoy asian fusion food and I am a vegetar...   \n",
       "\n",
       "                               test_query_1.response  \\\n",
       "0  <search_quality_reflection>\\nThe new search re...   \n",
       "\n",
       "                                  test_query_2.query  \\\n",
       "0  \\nI have a peanut allergy but I like thai food...   \n",
       "\n",
       "                               test_query_2.response  \\\n",
       "0  <search_quality_reflection>\\nThe focused query...   \n",
       "\n",
       "                                  test_query_3.query  \\\n",
       "0  \\nSuggest a low-carb breakfast recipe that inc...   \n",
       "\n",
       "                               test_query_3.response  \\\n",
       "0  <search_quality_reflection>\\nThe third search ...   \n",
       "\n",
       "                                  test_query_4.query  \\\n",
       "0  \\nSuggest a healthy dinner recipe for two peop...   \n",
       "\n",
       "                               test_query_4.response  \\\n",
       "0  <search_quality_reflection>\\nThe additional se...   \n",
       "\n",
       "                                  test_query_5.query  \\\n",
       "0  \\nI am on a ketogenic diet and need a dinner r...   \n",
       "\n",
       "                               test_query_5.response  ...  \\\n",
       "0  Unfortunately I could not find any recipes in ...  ...   \n",
       "\n",
       "  config.COARSE_SEARCH_KWARGS.lambda_mult config.COARSE_SEARCH_TYPE  \\\n",
       "0                                     0.5                       mmr   \n",
       "\n",
       "  config.DOWNLOAD_PATH                                    config.FILE_KEY  \\\n",
       "0                 data  recipes_w_cleaning_time_combined_features.parquet   \n",
       "\n",
       "  config.MAX_DOC_COUNT                          config.MODEL_ID  \\\n",
       "0                  150  anthropic.claude-3-sonnet-20240229-v1:0   \n",
       "\n",
       "  config.RERANKER_TOP_N  config.RETRIEVER  config.SELF_QUERY_API  \\\n",
       "0                     1  self_query_chain                 OpenAI   \n",
       "\n",
       "   config.SELF_QUERY_MODEL  \n",
       "0                   gpt-4o  \n",
       "\n",
       "[1 rows x 29 columns]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import S3 bucket JSON file.\n",
    "\n",
    "s3 = boto3.client('s3')\n",
    "bucket_name = 'test-api-results'\n",
    "file_key = 'demo_full'\n",
    "# Download it to Thomas' local laptop\n",
    "s3.download_file(bucket_name, file_key, f\"/Users/tl164/Downloads/{file_key}\")\n",
    "# Download it to Sagemaker instance \n",
    "# s3.download_file(bucket_name, file_key, f'../data/{file_key}')\n",
    "\n",
    "f = open(f'/Users/tl164/Downloads/{file_key}')\n",
    "\n",
    "# returns JSON object as \n",
    "# a dictionary\n",
    "data = json.load(f)\n",
    "\n",
    "f.close()\n",
    "\n",
    "response_df = pd.json_normalize(data)\n",
    "\n",
    "### Still need to format the dataframe into a certain way\n",
    "response_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm_judge_eval(query_question, query_response):\n",
    "    \n",
    "    eval_message = f\"\"\"\n",
    "    You are a helpful assistant and expert in reviewing cooking recipes.\n",
    "\n",
    "    Please look at the given user query, recipe generated by another LLM and follow the rubric below. Provide a score between 1-5 on how good the recipe is.\n",
    "\n",
    "    user query : \"{query_question}\"\n",
    "\n",
    "    Recipe generated by another LLM: \"{query_response}\"\n",
    "\n",
    "    Recipe review rubric: \n",
    "\n",
    "    Grading Scale (1-5)\n",
    "\n",
    "    5 - Exceptional Recipe:\n",
    "\n",
    "    1. Accuracy: The recipe is highly accurate and closely matches the user's query, including all specified ingredients, dietary restrictions, and desired cuisine type.\n",
    "    2. Clarity: The instructions are clear, easy to follow, and logically sequenced. Cooking times and temperatures are precise.\n",
    "    3. Creativity: The recipe demonstrates creativity, offering a unique or interesting twist on a classic dish or a novel combination of ingredients.\n",
    "    4. Completeness: The recipe includes all necessary details, such as ingredient measurements, preparation steps, serving suggestions, and any relevant tips or variations.\n",
    "    5. Healthiness: The recipe provides a balanced nutritional profile, aligning with any specified health goals or dietary considerations.\n",
    "    6. User Feedback: The recipe is likely to receive high ratings from users for both taste and ease of preparation.\n",
    "    4 - Very Good Recipe:\n",
    "\n",
    "    1. Accuracy: The recipe mostly matches the user's query with minor deviations or substitutions that still align with the user's dietary restrictions and preferences.\n",
    "    2. Clarity: The instructions are clear and easy to follow, with only minor areas that could benefit from additional detail.\n",
    "    3. Creativity: The recipe shows some creativity and presents an appealing dish, though it may not be as unique as a 5-rated recipe.\n",
    "    4. Completeness: The recipe includes most necessary details, but might miss a few minor tips or variations.\n",
    "    5. Healthiness: The recipe is generally healthy, though it may not be as nutritionally balanced as a 5-rated recipe.\n",
    "    6. User Feedback: The recipe is likely to receive good ratings from users, being tasty and reasonably easy to prepare.\n",
    "    3 - Good Recipe:\n",
    "\n",
    "    1. Accuracy: The recipe has a reasonable match with the user's query but may include some inaccuracies or ingredient substitutions that slightly alter the dish's nature.\n",
    "    2. Clarity: The instructions are generally clear but may have a few confusing steps or lack detailed guidance in some areas.\n",
    "    3. Creativity: The recipe is standard with minimal creativity or uniqueness.\n",
    "    4. Completeness: The recipe includes the essential details but lacks additional helpful information or suggestions.\n",
    "    5. Healthiness: The recipe is moderately healthy but may lack balance in terms of nutritional profile.\n",
    "    6. User Feedback: The recipe is expected to receive average ratings, being satisfactory but not outstanding in taste or ease of preparation.\n",
    "    2 - Fair Recipe:\n",
    "\n",
    "    1. Accuracy: The recipe has noticeable discrepancies from the user's query, potentially including ingredients that were supposed to be excluded due to dietary restrictions.\n",
    "    2. Clarity: The instructions are unclear or difficult to follow, with significant gaps or ambiguities.\n",
    "    3. Creativity: The recipe lacks creativity and may appear bland or uninspired.\n",
    "    4. Completeness: The recipe is missing several important details, such as precise measurements or key preparation steps.\n",
    "    5. Healthiness: The recipe is not particularly healthy and may have an unbalanced nutritional profile.\n",
    "    6. User Feedback: The recipe is likely to receive below-average ratings due to issues with taste, clarity, or preparation difficulty.\n",
    "    1 - Poor Recipe:\n",
    "\n",
    "    1. Accuracy: The recipe significantly deviates from the user's query, ignoring key dietary restrictions or preferences.\n",
    "    2. Clarity: The instructions are confusing, incomplete, or incorrect, making the recipe difficult or impossible to follow.\n",
    "    3. Creativity: The recipe is not creative and may seem haphazard or poorly thought out.\n",
    "    4. Completeness: The recipe is missing critical details, such as major ingredients, steps, or cooking times.\n",
    "    5. Healthiness: The recipe is unhealthy and lacks a balanced nutritional profile.\n",
    "    6. User Feedback: The recipe is likely to receive low ratings due to poor taste, difficulty in preparation, or failure to meet user expectations.\n",
    "\n",
    "    Return the output in JSON format with keys: \"Score\" (1-5), \"Reasoning\" (list of dicts with \"Accuracy\", \"Clarity\", \"Creativity\", \"Completeness\", \"Healthiness\", \"User feedback\").\n",
    "    \"\"\"\n",
    "\n",
    "    eval_resp = qdrant_rag_chain_eval.invoke(eval_message)\n",
    "    score  = json.loads(eval_resp['content'][0]['text'])['Score']\n",
    "    reasoning = json.loads(eval_resp['content'][0]['text'])['Reasoning']\n",
    "    print(eval_resp['content'][0]['text'])\n",
    "   \n",
    "    return score, reasoning\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm_gatekeeper(query_question, query_response):\n",
    "\n",
    "    eval_message = f\"\"\"\n",
    "    You are a helpful assistant and expert in reviewing and judging cooking recipes. \n",
    "    Please be as unbiased and impartial towards the recipe.\n",
    "    Please look at the given user query, recipe generated by another LLM. \n",
    "    Return if the response correctly follows the user's request, dietary restrictions and preferences. Answer, Yes or No.\n",
    "    user query : \"{query_question}\"\n",
    "    Recipe generated by another LLM: \"{query_response}\"\n",
    "    Return the output in JSON format with keys: \"Answer\" (Yes or No), \"Reasoning\" (Provide one sentence reasoning).\n",
    "    \"\"\"\n",
    "\n",
    "    eval_resp = qdrant_rag_chain_eval.invoke(eval_message)\n",
    "    answer  = json.loads(eval_resp['content'][0]['text'])['Answer']\n",
    "    reasoning = json.loads(eval_resp['content'][0]['text'])['Reasoning']\n",
    "    print(eval_resp['content'][0]['text'])\n",
    "   \n",
    "    return answer, reasoning\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"Score\": 5,\n",
      "    \"Reasoning\": [\n",
      "        {\n",
      "            \"Accuracy\": \"The recipe is highly accurate and closely matches the user's query, including all specified ingredients, dietary restrictions, and desired cuisine type.\",\n",
      "            \"Clarity\": \"The instructions are clear, easy to follow, and logically sequenced. Cooking times and temperatures are precise.\",\n",
      "            \"Creativity\": \"The recipe demonstrates creativity, offering a unique or interesting twist on a classic dish with the combination of coconut-ginger curry sauce and udon noodles.\",\n",
      "            \"Completeness\": \"The recipe includes all necessary details, such as ingredient measurements, preparation steps, serving suggestions, and relevant tips.\",\n",
      "            \"Healthiness\": \"The recipe provides a balanced nutritional profile, aligning with the user's vegetarian dietary considerations.\",\n",
      "            \"User Feedback\": \"The recipe is likely to receive high ratings from users for both taste and ease of preparation.\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"Answer\": \"Yes\",\n",
      "    \"Reasoning\": \"The recipe generated by the other LLM aligns with the user's request for a vegetarian Asian fusion recipe, providing a detailed list of ingredients and instructions for a Coconut-Ginger Curry Noodle Bowl.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "def append_llm_responses(df):\n",
    "    llm_scores = []\n",
    "    llm_score_reasoning = []\n",
    "    gate_keeper = []\n",
    "    gate_keeper_reasoning = []\n",
    "    for index, row in response_df.iterrows():\n",
    "\n",
    "        # TODO : Change Test Query name and Test Query Response name\n",
    "        query_question = row['test_query_1.query']\n",
    "        query_response = row['test_query_1.response']\n",
    "        score, score_reasoning = llm_judge_eval(query_question, query_response)\n",
    "        gate_keeper_response, gate_keeper_response_reasoning = llm_gatekeeper(query_question, query_response)\n",
    "\n",
    "        llm_scores.append(score)\n",
    "        llm_score_reasoning.append(score_reasoning)\n",
    "        gate_keeper.append(gate_keeper_response)\n",
    "        gate_keeper_reasoning.append(gate_keeper_response_reasoning)\n",
    "    \n",
    "    # Append the LLM responses to the DataFrame\n",
    "    df['LLM Score'] = llm_scores\n",
    "    df['LLM Score Reasoning'] = llm_score_reasoning\n",
    "    df['LLM GateKeeper Judge'] = gate_keeper\n",
    "    df['LLM GateKeeper Judge Reasoning'] = gate_keeper_reasoning\n",
    "    return df\n",
    "\n",
    "# Call the function and get the updated DataFrame\n",
    "updated_df = append_llm_responses(response_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_df.to_csv(\"response_with_score.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
